<!DOCTYPE html>
	<head>
	<style>
		#mediaWrapper{
			margin: 0 auto;
			width: 90%;
			background: black;
			max-width:2000px;
			border-radius:4px;
			
		}
		.footerpod{background: white;}
		canvas{order: 20px solid green;width:97%;height: 200px;}
	.diva{margin-top: 0px;margin-bottom:0px;padding: 0px;width:100%;order:2px solid brown;position:relative;}
	.wr{
		position:relative;
		width: 100%;
		order-bottom: 1px solid silver;
	}
	.diva.dictor{border-bottom: 1px solid silver;}
	.diva.dictor::after{
		
		top:1em;
		left:2em;
		content:"Запись диктора";
		color:silver;
	
		position:absolute;}
		
		.diva.voice::after{
			top:1em;
		left:2em;
		content:"Ваша запись";
		color:silver;
		
		position:absolute;}
		}
	
	
	
	
	.podval{padding:20px;background:white;}
	.footerpod{
		margin: 0 auto;
		
	}
	 button{
   height: 50px;
	width: 75px;
	margin: 5px;
	background:orange;
	vertical-align:bottom;
	padding: 6px;
	margin: 5px;
	font-weight: bold;
	line-height:1.2;
}

button:hover{
    background: rgb(2, 106, 203);
    color: white;
    border-color: silver;
}

button[disabled], button[disabled]:hover {
    background: gray;
    color: rgb(148, 168, 181);
    border-color: silver;
}



@media screen and (max-width: 	1000px){
	
	
	.footerpod{
		margin: 0 auto;
	}
	.podval{text-align: center;}
	img{
		width:100px;
		height:100px;
		margin-top:4px;
		}
	button{
		olor:green;
		margin-top:10px;
		margin-bottom:10px;
		height:160px;
		font-size:46px;
		width: 100%;
		margin-left:0;
	}
}


	</style>
	</head>
	<body>
		
	<section id="mediaWrapper">
	<div class="wr">
	<div class="diva dictor">
	<canvas id="cnv"></canvas>
	</div>
	</div>
	<div class="wr">
	<div class="diva voice">
	<canvas id='recorded'></canvas>
	</div>
	</div>

    <div class="podval">
		<section class="footerpod">
		
		
		<img onclick="getBuf(this);" id="first" data-f="-1" data-disabled="true" src="/musik/left-arrow.svg"  width="50" height="50"/>
		
		<button id="dictor" data-f="0" onclick="getBuf(this);">Слушать диктора</button>
		
        <button id="record" data-record="Запись">Запись себя</button>
        <button id="play" disabled>Слушать себя</button>
        
       <img data-f="0" id="zweit" onclick="getBuf(this);" src="/musik/right-arrow.svg" width="50" height="50" data-disabled="false"/>
      
    
    </section>
    </div>
    </section>
    
    <div>
		
        <span id="errorMsg"></span>
    </div>
     <audio id="gum"></audio> 
    
    <p>здравствуйте. добро пожаловать. доброе утро. добрый день</p>
	<script>
	'use strict';
var audioContext, audioContext2, ctx3;
var audioElement = document.getElementById("myaudio");
var cnv = document.getElementById("cnv");
var ctx = cnv.getContext("2d");

var flag = false;
var track,analyser;
let x = 0;
let files = ["/musik/0001rus.wav", "/musik/0002rus.wav", "/musik/0003rus.wav", "/musik/0004rus.wav"];

var si = files.length;


function disabled(n){
	if(n < si){
		zweit.setAttribute("data-disabled", "false");
	}
	if(n > 0){
		first.setAttribute("data-disabled", "false");
	}
	if(n == 0){
		first.setAttribute("data-disabled", "true");
	}
	if(n == si - 1){

		zweit.setAttribute("data-disabled", "true");
		
	
	}
}

async function getBuf(e){
	if(e.getAttribute("data-disabled") && e.getAttribute("data-disabled") === "true"){
		return;
	}
	let n = Number(e.getAttribute("data-f"));
	
	if(n < 0){
		
		return;
	}
	disabled(n);
	if(n == si){
	
		return;
	}

	e.disabled = true;
	e.setAttribute("data-disabled", "true");
ctx3 = new AudioContext();

var audio3;

let data;


try{
data = await fetch(files[n]);
}catch(e){
	alert(e);
	return;
}
first.setAttribute("data-f", n - 1);
zweit.setAttribute("data-f", n + 1);

dictor.setAttribute("data-f", n);

let arrayBuffer = await data.arrayBuffer();

let decodedAudio = await ctx3.decodeAudioData(arrayBuffer)
audio3 = decodedAudio;
		console.log(audio3);
		const playSound = ctx3.createBufferSource();
  playSound.buffer = audio3;

		let analyser = ctx3.createAnalyser();
		 analyser.smoothingTimeConstant = 1.0;
		playSound.connect(analyser);
		 analyser.connect(ctx3.destination);
  
  playSound.start(ctx3.currentTime);
  
  analyser.fftSize = 2048;

let bufferLength =  analyser.frequencyBinCount;
console.log(bufferLength);
let dataArray = new Uint8Array(bufferLength);

if(!flag){
	ctx.clearRect(0,0,cnv.width, cnv.height);
	flag = true;
}

drawf();


var drawVisual3;
  
  function drawf(){
	 // alert('drawf')
	  drawVisual3 = requestAnimationFrame(drawf);
	  
	
	analyser.getByteTimeDomainData(dataArray);

	let d = dataArray;
	
	var sliceWidth =(cnv.width)/ bufferLength;
	
	ctx.lineWidth = 0.25;
	ctx.strokeStyle = "rgb(83,210,13)";
	
	ctx.beginPath();
ctx.moveTo(x, cnv.height/2);
	
	for (var i = 0; i < bufferLength; i+=cnv.width/2) {

		  const v = (d[i]) / 128.0;
 const y = (v * cnv.height) / 2.0;

  if (i === 0) {
   ctx.moveTo(x, y);
 
  } else {
    ctx.lineTo(x, y);
  
  }

  x += sliceWidth;
}
	ctx.stroke();
  }
  
  playSound.onended = function(){
	  cancelAnimationFrame(drawVisual3);
	  ctx3.close();
	  x=0;
	  e.disabled = false
	  e.setAttribute("data-disabled", "false")
	 disabled(n);
  
	  flag = false;
	  
	  }
  
}




let mediaRecorder;
let recordedBlobs;
let cnv2 = document.getElementById("recorded");
let ctx2 = cnv2.getContext("2d");



let audioCtx, flag2 = false, track2, analyser2,  x2 = 0;


const errorMsgElement = document.querySelector('span#errorMsg');

    
var recordedVideo = gum;
const recordButton = document.querySelector('button#record');
recordButton.addEventListener('click', async() => {
	//alert(recordButton.getAttribute("data-record"))
  if (recordButton.getAttribute("data-record") === 'Запись') {
	  recordButton.setAttribute("data-record", "no");
	  const constraints = {
    audio: {
      echoCancellation: {exact: true}
    }
    
  };
 console.log('Using media constraints:', constraints);
  await init(constraints);
	  
	  
    startRecording();
  } else {
	 // alert("stop");
    stopRecording();
    recordButton.setAttribute("data-record", 'Запись');
    recordButton.textContent = "Запись себя";
    playButton.disabled = false;
   
    
  }
});

const playButton = document.querySelector('button#play');
playButton.addEventListener('click', () => {
  const mimeType = 'audio/webm';
  const superBuffer = new Blob(recordedBlobs, {type: mimeType});
  recordedVideo.src = null;
  recordedVideo.srcObject = null;
  recordedVideo.src = window.URL.createObjectURL(superBuffer);
 
  recordedVideo.play();
  
	
  recordedVideo.onplay = function(){
	 
	  getSound2();
	  
  }
});



function handleDataAvailable(event) {
  console.log('handleDataAvailable', event);
  if (event.data && event.data.size > 0) {
    recordedBlobs.push(event.data);
  }
}


function startRecording() {
  recordedBlobs = [];
 
  const options = {mimeType: 'audio/webm'};

  try {
    mediaRecorder = new MediaRecorder(window.stream, options);
  } catch (e) {
    console.error('Exception while creating MediaRecorder:', e);
    errorMsgElement.innerHTML = `Exception while creating MediaRecorder: ${JSON.stringify(e)}`;
    return;
  }

  console.log('Created MediaRecorder', mediaRecorder, 'with options', options);
  recordButton.textContent = 'Стоп';
  playButton.disabled = true;
 
 
  mediaRecorder.onstop = (event) => {
    console.log('Recorder stopped: ', event);
    console.log('Recorded Blobs: ', recordedBlobs);
  };
  mediaRecorder.ondataavailable = handleDataAvailable;
  mediaRecorder.start();
  console.log('MediaRecorder started', mediaRecorder);
}

function stopRecording() {
  mediaRecorder.stop();
 
}

function handleSuccess(stream) {

  console.log('getUserMedia() got stream:', stream);
  window.stream = stream;

  const gumVideo = document.querySelector('audio#gum');
  gumVideo.srcObject = stream;

}

async function init(constraints) {
  try {
    const stream = await navigator.mediaDevices.getUserMedia(constraints);
    handleSuccess(stream);
  } catch (e) {
    console.error('navigator.getUserMedia error:', e);
    errorMsgElement.innerHTML = `navigator.getUserMedia error:${e.toString()}`;
  }
}


		
		async function getSound2(){
	
			audioCtx = new AudioContext();
			await audioCtx.resume();


	if(!flag2)ctx2.clearRect(0, 0, cnv2.width, cnv2.height);

 
 flag2 = true;
if(!track2){
		track2 = audioCtx.createMediaElementSource(document.getElementById("gum"));
		 analyser2 = audioCtx.createAnalyser();
		 analyser2.smoothingTimeConstant = 1.0;
		 track2.connect(analyser2);
		 analyser2.connect(audioCtx.destination);
    }


	analyser2.fftSize = 2048;

	var bufferLength2 =  analyser2.frequencyBinCount;
	console.log(bufferLength2);
	var dataArray2 = new Uint8Array(bufferLength2);



draw2();


var drawVisual2;
		
		
		
		
function draw2(){

	drawVisual2 = requestAnimationFrame(draw2);
	
	analyser2.getByteTimeDomainData(dataArray2);

	let d = dataArray2;
	
	var sliceWidth2 =(cnv2.width)/ bufferLength2;
	
	

	ctx2.lineWidth = 0.25;
	ctx2.strokeStyle = "rgb(83,210,13)";
	
	ctx2.beginPath();
for (var i = 0; i < bufferLength2; i+= 180){
		  const v2 = (d[i]) / 128.0;
			const y2 = (v2 * cnv2.height) / 2.0;

  if (i === 0) {
   ctx2.moveTo(x2, y2);
 
  } else {
    ctx2.lineTo(x2, y2);
  
  }

  x2 += sliceWidth2;
}
	ctx2.stroke();
}

gum.onended = function(e){
	
	cancelAnimationFrame(drawVisual2);
	x2 = 0;
   
	flag2 = false;
}

}





	</script>
	</body></html>
